{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n",
    "from utils.tools import dotdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data_provider.data_factory import data_provider\n",
    "\n",
    "from models import Autoformer\n",
    "from data_provider.data_loader import Dataset_Pred\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac2883f0270230",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "args = dotdict()\n",
    "args.target = 'e_mu_current'\n",
    "args.des = 'test'\n",
    "args.dropout = 0.05\n",
    "args.num_workers = 10\n",
    "args.gpu = 0\n",
    "args.lradj = 'type1'\n",
    "args.devices = '0'\n",
    "args.use_gpu = True\n",
    "args.use_multi_gpu = False\n",
    "\n",
    "args.freq = 't'\n",
    "args.checkpoints = './checkpoints/'\n",
    "args.bucket_size = 4\n",
    "args.n_hashes = 4\n",
    "args.is_trainging = True\n",
    "args.root_path = './datasets/'\n",
    "args.data_path ='non_outliers_step=120_log_inf_train=0.9.csv'\n",
    "# args.data_path ='outliers_step=120_log_inf_train=0.9.csv' \n",
    "args.model_id='qber_96_48_120_loginf_s_non_outliers'\n",
    "args.model = 'Autoformer'\n",
    "args.data = 'custom'\n",
    "args.features = 'MS'\n",
    "args.seq_len = 96\n",
    "args.label_len = 48\n",
    "args.pred_len = 1\n",
    "args.e_layers = 6\n",
    "args.d_layers = 6\n",
    "args.n_heads = 8\n",
    "args.factor = 3\n",
    "args.enc_in = 6\n",
    "args.dec_in =6\n",
    "args.c_out = 6\n",
    "args.d_model = 512\n",
    "args.des = 'Exp'\n",
    "args.itr = 1\n",
    "args.d_ff = 2048\n",
    "args.moving_avg = 25\n",
    "args.factor = 1\n",
    "args.distil = False\n",
    "args.output_attention = True\n",
    "args.patience= 3\n",
    "args.learning_rate = 0.0001\n",
    "args.batch_size = 64\n",
    "args.embed = 'timeF'\n",
    "args.activation = 'gelu'\n",
    "args.use_amp = False\n",
    "args.loss = 'mse'\n",
    "args.train_epochs = 10\n",
    "\n",
    "exp = Exp_Main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4d9ba466f53f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setting='qber_96_48_120_loginf_s_non_outliers_Autoformer_custom_ftMS_sl96_ll48_pl1_dm512_nh8_el6_dl6_df2048_fc1_ebtimeF_dtFalse_Exp_0'\n",
    "\n",
    "best_model_path=f'./checkpoints/{setting}/checkpoint.pth'\n",
    "\n",
    "exp.model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb60c23890d30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset, pred_loader=data_provider(args, flag='pred')\n",
    "\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "    pass\n",
    "\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "print(batch_x_mark.shape)\n",
    "print(batch_y_mark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_x = torch.FloatTensor(batch_x).to(exp.device)\n",
    "batch_y = torch.FloatTensor(batch_y).to(exp.device)\n",
    "\n",
    "batch_x_mark = torch.FloatTensor(batch_x_mark).to(exp.device)\n",
    "batch_y_mark = torch.FloatTensor(batch_y_mark).to(exp.device)\n",
    "\n",
    "exp._predict(batch_x, batch_y, batch_x_mark, batch_y_mark)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a51be16b4f17237c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.predict(setting,pred_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b021c95757f99dc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24878b899d765f02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_autoformer(df_raw, seq_len, label_len,target='e_mu_current',freq='t'):\n",
    "    pred_len=1\n",
    "\n",
    "    cols = list(df_raw.columns)\n",
    "    cols.remove(target)\n",
    "    cols.remove('date')\n",
    "\n",
    "    df_raw = df_raw[['date'] + cols + [target]]\n",
    "    border1 = len(df_raw) - seq_len - pred_len\n",
    "    border2 = len(df_raw)\n",
    "\n",
    "    cols_data = df_raw.columns[1:]\n",
    "    df_data = df_raw[cols_data]\n",
    "\n",
    "    data = df_data.values\n",
    "\n",
    "    tmp_stamp = df_raw[['date']][border1:border2]\n",
    "    tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "    pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=pred_len + 1, freq=freq)\n",
    "\n",
    "    df_stamp = pd.DataFrame(columns=['date'])\n",
    "    df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
    "\n",
    "    df_stamp = df_raw[['date']][border1:border2]\n",
    "    df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "\n",
    "    df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "    df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "    df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "    df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "    df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
    "    df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
    "    data_stamp = df_stamp.drop(['date'], axis=1).values\n",
    "\n",
    "    data_x = data[border1:border2]\n",
    "    data_y = data[border1:border2]\n",
    "\n",
    "    s_begin = 0\n",
    "    s_end = s_begin + seq_len\n",
    "    r_begin = s_end - label_len\n",
    "    r_end = r_begin + label_len + pred_len\n",
    "\n",
    "    seq_x = data_x[s_begin:s_end]\n",
    "    seq_y = data_y[r_begin:r_begin + label_len]\n",
    "    seq_x_mark = data_stamp[s_begin:s_end]\n",
    "    seq_y_mark = data_stamp[r_begin:r_end+1]\n",
    "\n",
    "    \n",
    "    return seq_x, seq_y, seq_x_mark, seq_y_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea871a1e0039977",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('datasets/non_outliers_step=120_log_inf_test=0.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path=f'./checkpoints/{setting}/model.pth'\n",
    "\n",
    "model = Autoformer.Model(args).float()\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "model.eval()\n",
    "device='cuda'\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70593ce68255624"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i  in tqdm(range(len(df)-args.seq_len)):\n",
    "        \n",
    "        df_tmp=df.iloc[i:i+args.seq_len+args.pred_len]\n",
    "        \n",
    "        seq_x, seq_y, seq_x_mark, seq_y_mark=preprocess_autoformer(df_tmp,args.seq_len, args.label_len )\n",
    "        \n",
    "        batch_x = torch.FloatTensor(seq_x).unsqueeze(0).to(device)\n",
    "        batch_y = torch.FloatTensor(seq_y).unsqueeze(0).to(device)\n",
    "        batch_x_mark = torch.FloatTensor(seq_x_mark).unsqueeze(0).to(device)\n",
    "        batch_y_mark = torch.FloatTensor(seq_y_mark).unsqueeze(0).to(device)\n",
    "\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "\n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        if exp.args.output_attention:\n",
    "            outputs = outputs[0]\n",
    "\n",
    "        f_dim = -1 if args.features == 'MS' else 0\n",
    "        outputs = outputs[:, -args.pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -args.pred_len:, f_dim:].to(device)\n",
    "\n",
    "\n",
    "        pred = outputs.detach().cpu().numpy()[0]  # .squeeze()\n",
    "        true = batch_y.detach().cpu().numpy()[0]  # .squeeze()\n",
    "\n",
    "        preds.append(pred[-args.pred_len:])\n",
    "        trues.append(true[-args.pred_len:])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d401e364576c2a61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "print(batch_x_mark.shape)\n",
    "print(batch_y_mark.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa0f31b88c3c8f5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7339c8f339e8ee0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trues=np.array(trues)\n",
    "preds=np.array(preds)\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(np.exp(trues[:,0,0]))\n",
    "plt.plot(np.exp(preds[:,0,0]))\n",
    "plt.legend(['true', 'predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trues[:,0,0]/np.exp(preds[:,0,0]))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71ff26995067d006"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
